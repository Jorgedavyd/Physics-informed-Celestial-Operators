\documentclass[draft]{agujournal2019}
\usepackage{url} %this package should fix any errors with URLs in refs.
\usepackage{lineno}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[inline]{trackchanges} %for better track changes. finalnew option will compile document with changes incorporated.
\usepackage{soul}
\linenumbers
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\draftfalse

\journalname{Machine Learning and Computation}


\begin{document}

\title{Physics informed Machine Learning for Celestial Mechanics: The N-body problem}

%% ------------------------------------------------------------------------ %%
%
%  AUTHORS AND AFFILIATIONS
%
%% ------------------------------------------------------------------------ %%

% Authors are individuals who have significantly contributed to the
% research and preparation of the article. Group authors are allowed, if
% each author in the group is separately identified in an appendix.)

% List authors by first name or initial followed by last name and
% separated by commas. Use \affil{} to number affiliations, and
% \thanks{} for author notes.
% Additional author notes should be indicated with \thanks{} (for
% example, for current addresses).

% Example: \authors{A. B. Author\affil{1}\thanks{Current address, Antartica}, B. C. Author\affil{2,3}, and D. E.
% Author\affil{3,4}\thanks{Also funded by Monsanto.}}

\authors{Jorge Enciso}


% \affiliation{1}{First Affiliation}
% \affiliation{2}{Second Affiliation}
% \affiliation{3}{Third Affiliation}
% \affiliation{4}{Fourth Affiliation}

\affiliation{=number=}{=Affiliation Address=}
%(repeat as many times as is necessary)

%% Corresponding Author:
% Corresponding author mailing address and e-mail address:

% (include name and email addresses of the corresponding author.  More
% than one corresponding author is allowed in this LaTeX file and for
% publication; but only one corresponding author is allowed in our
% editorial system.)

% Example: \correspondingauthor{First and Last Name}{email@address.edu}

\correspondingauthor{Jorge Enciso}{jorged.encyso@gmail.com}

\begin{keypoints}
\item Celestial mechanics
\item N-body problem
\item Physics informed Neural Networks (PINNs)
\end{keypoints}

\begin{abstract}
This work presents a novel approach to solving the N-body problem in celestial mechanics using Physics-Informed Neural Networks (PINNs). By incorporating Hamilton's equations directly into the neural network architecture through the loss function, we develop a universal approximator that inherently preserves fundamental physical properties such as energy conservation and phase space incompressibility. Our methodology embeds the classical gravitational potential function and kinetic energy transformations into the network's learning process, eliminating the need for extensive training datasets typically required in traditional machine learning approaches. The network is trained using a composite loss function that combines partial differential equation constraints with initial condition requirements, allowing for dynamic adaptation to various mass configurations and initial states. Through comparison with conventional numerical solvers, we demonstrate that our approach maintains comparable accuracy while offering significant computational advantages, particularly for systems requiring multiple evaluations with varying initial conditions. This work bridges the gap between classical celestial mechanics and modern machine learning techniques, offering a promising framework for efficient and physically consistent simulation of gravitational systems.
\end{abstract}

\section{Introduction}

The three-body problem is a cornerstone of celestial mechanics and dynamical systems, describing the motion of three masses under mutual gravitational interaction. Its significance lies not only in its applications to astrophysics but also in its foundational role in chaos theory and nonlinear dynamics. First formulated in \cite{newton1833philosophiae} (1687), the problem has challenged mathematicians and physicists for centuries due to its non-integrability.

Initial efforts to address the three-body problem employed analytical methods. Leonhard Euler and Joseph-Louis Lagrange, in the 18th century, derived specific solutions for simplified cases, such as collinear configurations \cite{euler} (Euler, 1765) and equilateral triangle configurations \cite{Lagrange}(Lagrange, 1772). These solutions revealed equilibrium points—now known as Eulerian and Lagrangian points—and their stability properties.

Later, Henri Poincaré demonstrated the impossibility of a general analytical solution, showing that the system's behavior is inherently chaotic and sensitive to initial conditions \cite{Poincare}(Poincaré, 1890). Poincaré’s work laid the foundation for modern chaos theory, emphasizing the necessity of numerical methods for exploring the dynamics of such systems.

Karl Sundman (1912) made significant progress by proving that a convergent series solution exists for the three-body problem under specific conditions, albeit impractical due to its slow convergence. Modern numerical techniques have since become the primary tool for studying the three-body problem and its generalization to N-body systems. Advances in computational methods have uncovered remarkable periodic solutions, such as the figure-eight orbit discovered by Chenciner and Montgomery (2000).

Numerical approaches have also highlighted the chaotic nature of three-body interactions, where small perturbations in initial conditions can lead to vastly different trajectories (Laskar, 1994). Such findings underscore the necessity of computational precision and innovative techniques for long-term predictions.

Recent years have seen the rise of universal approximators, such as neural networks, in modeling complex dynamical systems. These methods leverage their capacity to approximate arbitrary functions, making them well-suited for learning the underlying physics of celestial mechanics. Zhang et al. (2020) demonstrated the utility of deep neural networks in predicting trajectories in chaotic systems, offering a data-driven complement to traditional numerical solvers.

The current work aims to integrate the principles of physics-informed machine learning (PIML) with the study of celestial mechanics, focusing on the N-body problem. By embedding physical laws into neural networks, PIML approaches ensure adherence to conservation principles and other constraints, enhancing both accuracy and interpretability. The objective is to develop models that combine the precision of numerical methods with the efficiency and scalability of machine learning, paving the way for new insights into the dynamics of multi-body gravitational systems.

Through this synthesis of classical mechanics, numerical methods, and modern machine learning, this work seeks to advance our understanding of celestial mechanics and provide robust tools for addressing longstanding challenges in the field.

\section{Related Work}
\subsection{Three-body problem — From Newton to supercomputer plus machine learning}
\cite{Liao_2022} identifies periodic orbits within three-body systems with data-driven methods. Historically, only a limited number of such orbits were discovered over three centuries. The authors introduce an innovative approach that leverages machine learning, specifically artificial neural networks (ANNs), to systematically uncover planar periodic orbits for three-body systems with arbitrary masses. By starting with a known periodic orbit, their method iteratively expands the set of known orbits, effectively training the ANN to predict accurate periodic orbits across various mass configurations. This approach not only broadens the understanding of three-body dynamics but also underscores the potential of combining high-performance computing with artificial intelligence to tackle complex problems in celestial mechanics.
\subsection{Newton vs the machine: solving the chaotic three-body problem using deep neural networks}
\cite{Breen_2020} address the computational challenges inherent in solving the three-body problem due to its chaotic nature. Traditional numerical methods often demand extensive computational resources and time to achieve accurate solutions. To mitigate this, the authors trained a deep artificial neural network (ANN) on a dataset of solutions generated by high-precision numerical integrators. Their findings demonstrate that the ANN can predict the motions of three-body systems over bounded time intervals with fixed computational costs, achieving speeds up to 100 million times faster than conventional solvers. This approach holds promise for efficiently simulating complex many-body systems, such as those involving black-hole binaries or dense star clusters.
\subsection{Physics Informed Deep Learning: Data-driven Solutions of Nonlinear Partial Differential Equations}
\cite{raissi2017physicsinformeddeeplearning} introduces Physics-Informed Neural Networks (PINNs) as a novel approach to solving problems governed by partial differential equations (PDEs). PINNs incorporate the underlying physical laws, expressed as PDEs, directly into the neural network's loss function, enabling them to learn solutions while respecting the governing equations. This eliminates the need for labeled data, relying instead on the residuals of the PDEs to guide the training. The study demonstrates the application of PINNs to a variety of forward and inverse problems, such as fluid dynamics and heat conduction. The framework is particularly useful for problems with limited observational data or where traditional numerical solvers are computationally expensive. PINNs offer a generalizable and efficient alternative for modeling complex physical systems.

\section{Problem statement}
On a closed system, the governing laws are described by the minimal action principle. The current work adheres to this principle as it derives the Euler-Lagrange equations, from which we can induce a Legendre transform that turns into the hamiltonian formulation:
\begin{align}
    \mathcal{H}\left(\mathbf{q}, \mathbf{p}\right) &= K\left(\mathbf{p}\right)+ U\left(\mathbf{q}\right) \\
    \dot{\mathbf{q}} &= \nabla_\mathbf{p} \mathcal{H} \\
    \dot{\mathbf{p}} &= - \nabla_\mathbf{q} \mathcal{H}
\end{align}
In this case, we adhere to the classical gravitational potential function for the $N$ bodies and kinetic energy transformed to the desired phase space:
\begin{align*}
    U(\mathbf{q}) &= - G \sum_{1 \leq i \leq n \leq N} \frac{m_i m_n}{\norm{\mathbf{r}_i\left(\mathbf{q}\right) - \mathbf{r}_n\left(\mathbf{q}\right)}}_2 \\
    K(\mathbf{p}) &= \sum_{i = 1}^{N} \frac{\mathbf{p}_i^2\left(\mathbf{p}\right)}{2 m_i}
\end{align*}

$G$ being the gravitational constant, for each cartesian $\mathbf{p}_i$ and $\mathbf{r}_i$ as functions of the generalized coordinates $\mathbf{p}$ and $\mathbf{q}$ respectively within our phase space $\mathcal{P}$. We also remind the reader of the properties of this system in the appendix section.

Hence, we are looking for a universal approximator that can resemble the properties and mechanics described by this system:
\begin{align*}
    \mathcal{H}_\theta &\colon \mathcal{P} \to \mathbb{R} \\
    \dot{\mathbf{q}} = \frac{\partial \mathcal{H}}{\partial \mathbf{\theta}} \frac{\partial \mathbf{\theta}}{\partial \mathbf{p}} &= \nabla_\mathbf{p} \nabla_\theta \mathcal{H}_\theta \\
    \dot{\mathbf{p}} = - \frac{\partial \mathcal{H}}{\partial \mathbf{\theta}} \frac{\partial \mathbf{\theta}}{\partial \mathbf{q}} &= - \nabla_\mathbf{q} \nabla_\theta \mathcal{H}_\theta \\
\end{align*}

We finally define the following loss function to solve the system:

\begin{equation}
    \mathcal{L}_{PDE} &= \norm{\int_\mathcal{P} \dot{\mathbf{p}} + \nabla_\mathbf{q} \nabla_\theta \mathcal{H}_\theta d(\boldsymbol{\lambda} (t))}^2 + \norm{\int_\mathcal{P} \dot{\mathbf{q}} - \nabla_\mathbf{p} \nabla_\theta \mathcal{H}_\theta d(\boldsymbol{\lambda} (t))}^2 \\
\end{equation}
for some $\boldsymbol{\lambda} (t) \colon \mathbb{R}^+ \to \mathbb{R}^N$ defining the paths of the $N$ bodies.

The initial conditions will be defined randomly for each iteration. A rectangular geometry is generally chosen to be our problem geometry within the $\mathbb{R}^2$ simulation. Finally, the loss function is:
\begin{align*}
    \mathcal{L} = \alpha_0 \mathcal{L}_{PDE} + \alpha_1 \mathcal{L}_{Initial}
\end{align*}

The present work's hypothesis is the existence of some function that embodies the whole dynamics of the system.

\section{Results}
Architecture configuration for neural networks

Bodies and masses configurations with results against numerical solvers

\section{Conclusion}
This work presents a novel approach to solving the N-body problem using physics-informed neural networks. By incorporating the Hamilton's equations for gravitational interactions directly into the neural network architecture through the loss function, we have demonstrated that it is possible to create a universal approximator that preserves the fundamental physical properties of celestial mechanical systems, including energy conservation and phase space incompressibility.

Our results show that the physics-informed neural network approach offers several advantages over traditional numerical solvers. First, once trained, the network provides fast inference times for different initial conditions without requiring additional numerical integration. Second, the built-in physical constraints ensure that the solutions maintain essential conservation laws, which is crucial for long-term stability predictions in celestial mechanics without an specialized numerical solver creating a dataset for a data-driven loss function.

The comparison with conventional numerical solvers demonstrates that our approach achieves comparable accuracy while providing significant computational efficiency gains for repeated evaluations. This is particularly valuable for applications requiring multiple simulations with varying initial conditions, such as space mission planning or astronomical event prediction.

Future work could explore several promising directions:
\begin{enumerate}
    \item Extending the architecture to handle variable numbers of bodies
    \item Incorporating additional physical constraints such as angular momentum conservation
    \item Developing adaptive training strategies for different mass ratios and orbital configurations
    \item Investigating the network's capability to identify and classify different types of orbital behaviors
\end{enumerate}

In conclusion, this work demonstrates the potential of physics-informed neural networks as a powerful tool for celestial mechanics, offering a balance between computational efficiency and physical accuracy. The approach opens new possibilities for studying complex gravitational systems and could complement existing numerical methods in astronomical applications.

\section{Appendix}
\appendix
\section{The Principle of Least Action}
\begin{definition}[The Action Integral]
    The action is a scalar quantity describing the balance between the kinetic and potential energy in a physical system. It can be described as follows given some generalized coordinates $\mathbf{q}$:
    \begin{align*}
        A\left[ \matbf{q}(t) \right] = \int_{t_1}^{t_2} \mathcal{L}\left(\mathbf{q}, \dot{\mathbf{q}}, t\right) dt
    \end{align*}
\end{definition}

being $\mathcal{L}$ the Lagrangian:

\begin{align*}
    \mathcal{L} \left(\mathbf{q}, \dot{\mathbf{q}}, t \right) = \sum_{i = 1}^{3N} \frac{m_i \dot{q}_i^2}{2} - U(\mathbf{q})
\end{align*}

\begin{definition}[The Principle of Least Action]
    The Principle of Least Action states that a path taken by a physical system has a stationary values for the system's action. This means, similar paths near one another have very similar action values.
    \begin{align*}
        \delta A\left[ \matbf{q}(t) \right] = 0
    \end{align*}
    We can develop this formulation to get the Euler-Lagrange equation:
    \begin{align*}
        \delta A\left[ \matbf{q}(t) \right] &= \delta \int_{t_1}^{t_2} \mathcal{L}\left(\mathbf{q}, \dot{\mathbf{q}}, t\right) dt \\
        0 = \int_{t_1}^{t_2} \left( \frac{\partial \mathcal{L}}{\partial \mathbf{q}} \cdot \delta \mathbf{q} + \frac{\partial \mathcal{L}}{\partial \dot{\mathbf{q}}} \cdot \delta \dot{\mathbf{q}} \right)dt &= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{q}} \cdot \delta q \right) \Big|_{t_1}^{t_2} + \int_{t_1}^{t_2} \left( \frac{\partial \mathcal{L}}{\partial \mathbf{q}} - \frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot{\mathbf{q}}}  \right) \delta q dt
    \end{align*}
    Given the conditions of the Least Action Principle, the first term vanishes, leaving the second term equal to zero, leading to the Euler-Lagrange equation:
    \begin{equation}
        \frac{\partial \mathcal{L}}{\partial \mathbf{q}} = \frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot{\mathbf{q}}}
    \end{equation}
\end{definition}

\section{The Hamiltonian Formulation}
We first introduce a Legendre tranformation to the Lagrangian given the following equality:
\begin{align*}
    \mathbf{p} = \frac{\partial \mathcal{L}}{\partial \mathbf{q}}
\end{align*}

Given the Legendre transformation formulation given $s = f'(x)$ and an inverse transformation $g$ such that $g^{-1}(s) = x$:

\begin{align*}
    \hat{f}(s) = f(g^{-1}(s)) - s \cdot g^{-1}(s)
\end{align*}

We can rewrite the Lagrangian in terms of the momenta $\mathbf{p}$ as follows:

\begin{align*}
    \hat{\mathcal{L}}(\mathbf{q}, \mathbf{p}) &= \mathcal{L}(\mathbf{q}, \dot{\mathbf{q}}(\mathbf{p})) - \nabla_{\dot{\mathbf{q}}} \mathcal{L} \cdot \dot{q} \\
    \hat{\mathcal{L}}(\mathbf{q}, \mathbf{p}) &= \sum_{i = 1}^{3N} \frac{p_i}{2m_i} - U(\mathbf{q}) - \nabla_{\dot{\mathbf{q}}} \mathcal{L} \cdot \dot{q} \\
    \hat{\mathcal{L}}(\mathbf{q}, \mathbf{p}) &= - \sum_{i = 1}^{3N} \frac{p_i}{2m_i} - U(\mathbf{q})
\end{align*}

The negative of this transformation ($-\hat{\mathcal{L}}$) is the hamiltonian $\mathcal{H}$, if we replace it in the Euler-Lagrange equations, we can induce the mechanical equations:
\begin{align*}
    \dot{\mathbf{q}} &= \nabla_\mathbf{p} \mathcal{H} \\
    \dot{\mathbf{p}} &= - \nabla_\mathbf{q} \mathcal{H} \\
\end{align*}

\begin{definition}[Properties of the Hamiltonian]
    The hamiltonian formulation leads to all the foundational energy principles as it represents the total energy of a system.
    \begin{align*}
        \frac{d\mathcal{H}}{dt} = \nabla_\mathbf{q} \mathcal{H} \cdot \dot{\mathbf{q}} + \nabla_\mathbf{p} \mathcal{H} \cdot \dot{\mathbf{p}} = - \mathbf{p} \cdot \dot{\mathbf{q}} + \dot{\mathbf{q}} \cdot \dot{\mathbf{p}} = 0
    \end{align*}
    This means that the total energy of a closed hamiltonian system is conserved through time.
    Moreover, if we compute the divergence of a velocity field described within the hamiltonian formulation:
\begin{align*}
    \mathbf{x} &= (\mathbf{q}, \mathbf{p}) \\
    \dot{\mathbf{x}} &= (\dot{\mathbf{q}}, \dot{\mathbf{p}}) \\
    \nabla_\mathbf{x} \cdot \dot{\mathbf{x}} = \nabla_\mathbf{q} \cdot \dot{\mathbf{q}} + \nabla_\mathbf{p} \cdot \dot{\mathbf{p}} &= \nabla_\mathbf{q} \cdot \nabla_\mathbf{p} \mathcal{H} - \nabla_\mathbf{p} \cdot \nabla_\mathbf{q} \mathcal{H} = 0 \\
    \nabla_\mathbf{x} \cdot \dot{\mathbf{x}} &= 0
\end{align*}
This defines the incompressibility ($\nabla \cdot u = 0$) of a hamiltonian system.

\end{definition}


%%%%%%%%%%%%%%
% Acronyms
%   \begin{acronyms}
%   \acro{Acronym}
%   Definition here
%   \acro{EMOS}
%   Ensemble model output statistics
%   \acro{ECMWF}
%   Centre for Medium-Range Weather Forecasts
%   \end{acronyms}

%
%%%%%%%%%%%%%%
% Notation
%   \begin{notation}
%   \notation{$a+b$} Notation Definition here
%   \notation{$e=mc^2$}
%   Equation in German-born physicist Albert Einstein's theory of special
%  relativity that showed that the increased relativistic mass ($m$) of a
%  body comes from the energy of motion of the body—that is, its kinetic
%  energy ($E$)—divided by the speed of light squared ($c^2$).
%   \end{notation}
% Please use ONLY \cite and \citeA for reference citations.
% \cite for parenthetical references
% ...as shown in recent studies (Simpson et al., 2019)
% \citeA for in-text citations
% ...Simpson et al. (2019) have shown...
%
%
%...as shown by \citeA{jskilby}.
%...as shown by \citeA{lewin76}, \citeA{carson86}, \citeA{bartoldy02}, and \citeA{rinaldi03}.
%...has been shown \cite{jskilbye}.
%...has been shown \cite{lewin76,carson86,bartoldy02,rinaldi03}.
%... \cite <i.e.>[]{lewin76,carson86,bartoldy02,rinaldi03}.
%...has been shown by \cite <e.g.,>[and others]{lewin76}.
%
% apacite uses < > for prenotes and [ ] for postnotes
% DO NOT use other cite commands (e.g., \citet, \cite, \citeyear, \citealp, etc.).
% \nocite is okay to use to add references from your Supporting Information
%
\bibliography{agusample}

\end{document}
