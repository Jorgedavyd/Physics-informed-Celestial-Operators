defaults:
  - modulus_default
  - scheduler: tf_exponential_lr
  - optimizer: adam
  - loss: sum
  - _self_

scheduler:
  decay_rate: 0.95
  decay_steps: 4000

model:
  in_features: 3
  hidden_layers: [10, 32, 10, 3]
  activations: [ReLU, ReLU, null, null]

training:
  rec_validation_freq: 1000
  rec_inference_freq: 2000
  rec_monitor_freq: 1000
  rec_constraint_freq: 2000
  max_steps: 10000

batch_size:
  bc: 1000
  pde: 1000

graph:
  func_arch: true
